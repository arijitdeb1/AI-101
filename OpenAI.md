# ![ScreenShot](/images/OpenAI.PNG?raw=true)
OpenAI is an artificial intelligence research organization that aims to ensure AI benefits all of humanity. Founded in December 2015, OpenAI conducts cutting-edge research in AI, developing advanced machine learning models and systems. The organization is known for creating widely recognized AI technologies, including:

**GPT (Generative Pre-trained Transformer)**: A series of language models capable of understanding and generating human-like text. GPT-3, one of its most famous models, can perform a variety of tasks such as translation, question answering, and content creation.

**Codex**: An AI model that powers GitHub Copilot, which assists developers by generating code snippets, reducing the time and effort needed for programming tasks.

**DALL-E**: A model capable of generating images from textual descriptions, showcasing the ability to create visual content based on detailed prompts.

OpenAI operates with a mission to ensure that artificial general intelligence (AGI)—highly autonomous systems that outperform humans at most economically valuable work—benefits all of humanity. It promotes collaboration and transparency, sharing its research findings and encouraging the responsible use and development of AI.


# OpenAI APIs 
These are a set of application programming interfaces provided by OpenAI that allow developers to integrate powerful AI models into their applications. These APIs give developers access to state-of-the-art AI capabilities, enabling them to build and enhance a wide range of applications with natural language understanding, generation, and other AI functionalities.
Open AI playground provides access to all working models like GPT 3.5, GPT 4.0 with basic subscription which is cost effective compared to ChatGPT subscriptions.
Open AI exposes various APIs across multiple AI capabilities as below:

![ScreenShot](/images/open ai apis.PNG?raw=true)

** _Please refer Open AI API Reference for more details_

## How to use Open AI APIs - 
   1. Login to https://platform.openai.com/
   2. For first time users Open AI provides a $5 credit which will expire within 90 days. Post that we need to select a billing plan with min $5 and opt for a "Pay as you go" payment model. Refer Open AI API Rate Limits to understand the charges for different models.
      
      For payment plan, Go to **Settings icon >> Billing >> Create Plan**
      
      ** _subscriptions for ChatGPT are completely different from Open AI payment plans and are charged separately._
   3. Once plan is confirmed, generate a API Key. Go to **Dashboard >> API Keys >> Create new secret key**.
   4. Here on, we'll be using Postman to execute some of the popular APIs. Download attached Postman Collection - `OpenAI.postman_collection.json` and configure as below -
         
      - Import the `OpenAI` collection in Postman 
      - Select `OpenAI` collection >> Go to `Variables` Tab >> Set `OpenAIKey` with the generated api key from above
      - The collection has following apis - 
           
        - List Models - _Api to List all models available with ChatGPT_
        - Chat - _Api to start a chat_
        - Playground-* - _Apis to imitate Playground features(explained below)_
        - Dall.E - _Api for image generation_
        - Whisper - _Api to convert speech to text_. etc

## Open AI Playground
The OpenAI Playground is an interactive web-based tool that allows users to experiment with OpenAI's language models, such as GPT-3, in a user-friendly environment. It provides a simple interface where you can input text prompts and receive AI-generated responses, helping you explore the capabilities of these models without needing to write any code. This tool is particularly useful for testing different prompts, understanding how the models work, and getting a feel for their potential applications in various tasks like content generation, conversation simulation, and more. For any activity(chat/completion) on Playground, corresponding python/nodejs code can be generated using **`View Code`** capability 

### **`Playground - Chat`** 
provides an interface to work on ChatGPT like conversations using different GPT models. You can define 3 roles relevant to the conversation like -

**System** - Set only once. Set the context and configure the behavior of the Assistant. [_example - "You're an assistant with vast knowledge on cars"_]
      
**User** -  Set the actual content/request/prompt
      
**Assistant** - Set the response

Apart from that you can also set 

**Temperature** - The higher the temperature, more variety in the response generated by the assistant i.e different result with every try for same prompt. If Temperature=0 means 0 creativity and same response will be generated on each request

**Maximum Tokens/Stop sequences** - Token generation can be controlled using this attributes.

** _API and Playground requests will not be used to train any models_

### **`Playground - Completions`**

<< Legacy - not covered >>

### **`Playground - Assistants`**

The Assistants API allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and files to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, File Search, and Function calling. For details, refer How Assistant Work link below.

First we have setup an AI Assistant on Open AI Playground platform with below configurations - 
1. **Instructions** - You are a weather bot. Use uploaded knowledge base to answer questions about temperature of different places in India. When asked calculate  the average temperature of a place for a specific duration.  Respond "I don't know" if you're not sure of any answer.
2. **File search** - Enabled, Upload [weather.txt](https://github.com/arijitdeb1/AI-101/blob/main/weather.txt) having temperatures for different states of India on different dates.
3. **Code Interpreter** - Enabled

On executing RUN with a related prompt, the AI assistant will generate response from uploaded knowledge base. Any prompt to calculate anything(like average temperature of a place across different dates) will result in generation of python code to calculate avg temperature along with the correct output.

Second, let's try to call the above AI Assistant from a Python code. (Enabling **file_search** and **code_interpreter**)
- Refer [assistant-filesearch.py](https://github.com/arijitdeb1/AI-101/blob/main/assistant-filesearch.py) for the detailed code
- Replace the api-key with your key
- Execute **`pip install openai --upgrade`** before executing the file

Third, let's create and execute an AI Assistant with **Function Calling** capability
- Refer [assistant-functioncalling.py](https://github.com/arijitdeb1/AI-101/blob/main/assistant-functioncalling.py)
- Here the Assistant will use a function which calls yahoo finance apis to get the latest stock prices.
- Replace the api-key with your key

## Fine Tuning
If the generated response by existing LLM models are not as per your expectations, you can train and fine tune existing LLM models based on your data set following below steps -
   
1. Create a training dataset file with example input and outputs(JSONL format)
2. Tune the model using the dataset.
3. Use the tuned model.

### **`Fine Tuning on Playground`**
1. copy 10 such below contents in a json file.
        
        {"messages": [{"role": "system", "content": "You are a DevOps chatbot."}, {"role": "user", "content":"This tool is a platform used for containerization."}, {"role": "assistant", "content": "Docker"}]}
2. Convert the json to a JSONL file. Upload and use ChatGPT to convert the file to JSONL file by specifying below prompt. 
        
        ![ScreenShot](/images/jsonl-prompt.PNG?raw=true)
3. Refer attached [training-data-4-finetune.jsonl]()
4. Go to `Playground` >> `Fine-tuning` >> `Create`
5. ![ScreenShot](/images/tune-setup.PNG?raw=true) . Click `Create`.
6. OpenAI will start the fine tuning job and will take a while to complete.

   ![ScreenShot](/images/inprogress-tuning.PNG?raw=true)

   ![ScreenShot](/images/inprogress-tuning2.PNG?raw=true)
7. On success, a tuned new model will be created and can be visible under `Successful` tab

   ![ScreenShot](/images/tune-success.PNG?raw=true)
8. Go to `Playground` >> `Chat` >> Select the new `Fine Tuned` model from above. Input any 'user' content from the JSONL file in the user message prompt which will generate an output as specified by you in the JSONL file.

   ![ScreenShot](/images/post-tune.PNG?raw=true)

   Similar prompt if tried with any other model will generate something below

   ![ScreenShot](/images/pre-tune.PNG?raw=true)

### **`Fine Tuning using OpenAi Apis`**
<< ToDo >>

## Embeddings
Turn text into numbers, unlocking use cases like search.
Embedding models - text-embedding-3-small, text-embedding-3-large

OpenAI’s text embeddings measure the relatedness of text strings. Embeddings are commonly used for:

**_Search_** (where results are ranked by relevance to a query string)                                                                                    
**_Clustering_** (where text strings are grouped by similarity)                                                                   
**_Recommendations_** (where items with related text strings are recommended)                                                 
**_Anomaly detection_** (where outliers with little relatedness are identified)                        
**_Diversity measurement_** (where similarity distributions are analyzed)                     
**_Classification_** (where text strings are classified by their most similar label)

An embedding is a vector (list) of floating point numbers. The distance between two vectors measures their relatedness. Small distances suggest high relatedness and large distances suggest low relatedness.

Here is a sample code where we'll find the nearest match of a sentence from a group of sentences - 
1. Review and upload notebook file `api-openai-02-embeddings.ipynb` to [Google CoLab](https://colab.research.google.com/)
2. The code will calculate the embeddings for each sentence in the group 
   ![ScreenShot](/images/group_embedding.PNG?raw=true)
3. The code will now calculate the embedding for the input sentence.
   ![ScreenShot](/images/input_embedding.PNG?raw=true)
4. Now code will evaluate the most matching sentence in the group (_word `Cooking` is something that's common with input sentence_). A new column `similarity` has been identified which holds a float value. Higher this value, higher is matching proportion to the input sentence.
   
    ![ScreenShot](/images/embedding_similarity.PNG?raw=true)
5. So `Cooking can be a relaxing hobby` is closest match to input sentence.

## LangChain

![ScreenShot](/images/LangChain.png?raw=true)

<< ToDo >>

## Useful Links
* Open AI - https://platform.openai.com/
* OPen AI API References - https://platform.openai.com/docs/api-reference/introduction
* Open AI API Rate Limits - https://platform.openai.com/settings/organization/limits
* How Assistant Work - https://platform.openai.com/docs/assistants/how-it-works
* Fine Tuning - https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset